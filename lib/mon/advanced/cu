 Capped cls are fixed-size cls 
 that support high-throughput opers 
 that insert and retrieve docs 
 based on insertion order. 
 Capped cls work in a way sim to circular bffs:
  once a cl fills its allocated space,
   it makes room for new docs by overwriting
    the oldest docs in the cl.

  
Capped cls guar preservation of the insertion order.
 As a res, 
 queries do not need an ix to return docs in insertion order.
  Without this ixing overhead, 
  they can support higher insertion throughput.
Capped cls guar that insertion order is identical
 to the order on disk (natural order)
  and do so by prohibiting ups that increase doc size.
   Capped cls only allow ups that fit the orig doc size,
    which ensures a doc does not change its location on disk.
Capped cls auto rm the oldest docs in the cl 
without requiring scripts or explicit rm opers.
For ex,
 the oplog.rs cl that stores a log of the opers in a replica set 
 uses a capped cl.
  
  Consider the following potential use cases for capped cls:

Store log info generated by high-volume systems. 
Inserting docs in a capped cl without an ix 
is close to the speed of writing log info directly to a file system. 
Furthermore,
 the built-in first-in-first-out property maintains the order of events, while managing storage use.
Cache small amounts of data in a capped cls.
 Since caches are read rather than write heavy,
  you would either need to ensure that this cl always
   remains in the working set (i.e. in RAM) or accept some write penalty for the required ix or ixes.


Recommendations and Restrictions

You can only make in-place ups of docs. 
If the up operation causes the doc to grow beyond their orig size, the up operation will fail.
If you plan to up docs in a capped cl, 
create an ix so that these up opers do not require a table scan.
If you up a doc in a capped cl to a size smaller than its orig size, 
and then a secondary resyncs from the primary,
 the secondary will replicate and allocate space based on the current smaller doc size. 
 If the primary then receives an up which increases the doc back to its orig size,
  the primary will accept the up
   but the secondary will fail with a failing up:
   objects in a capped ns cannot grow error message.

To prevent this error, create your secondary
 from a snapshot of one of the other up-to-date members
 of the replica set.


 the only way  to guar the primary and secondary binary files are compatible
  is seeding the secondary with a filesystem snapshot

 
 MG Cloud Manager Backup snapshots 
 are insufficient in this sit 
 since you need more than the content
 of the secondary to match the primary.

You cannot delete docs from a capped cl.
 To rm all docs from a cl,
 use the drop() method to drop the cl.

You cannot shard a capped cl.

Capped cls  have an _id field and an ix on the _id field by default.

 Ensure uniqueness
 1)using the unique:    true option  to the createIndex() method
 or
 2) by using an ObjectId for the _id field.
  
  Alternately,
  you can use the autoIndexId option
  to create when creating the capped cl,
   as in the Query a Capped Collection procedure.

Use natural ordering
 to retrieve the most recently inserted elements
 from the cl efficiently.
This is (somewhat) analogous to tail on a log file.
The aggregation pipeline operator $out cannot write res to a capped cl.


Procedures

Create a Capped Collection
You must create capped cls explicitly using the createCollection() method, 
which is a helper in the mongo shell
for the create command.

When creating a capped cl
 you must specify the maximum size of the cl in bytes,
  which MG will pre-allocate for the cl.
  -size  includes a small amount of space for internal overhead.

db.createCollection( "log", { capped: true, size: 100000 } )
If the size field is less than or equal to 4096,
then the cl will have a cap of 4096 bytes.
 Otherwise,
  MG will raise the provided size
  to make it an integer multiple of 256.


Additionally,
 you may also specify a maximum number of docs
 for the cl using the max field

 as in the following doc:

db.createCollection("log", { capped : true, size : 5242880, max : 5000 } )

The size argument   always required,
 even when you specify max number of docs.
 MG will rm older docs if a cl reaches the maximum size limit
  before it reaches  maximum doc count.

Query a Capped Collection
If you perform a find() on a capped cl with 
no ordering specified, 
MG guars that the ordering
 of res is the same as the insertion order.

To retrieve docs in
reverse insertion order,
issue find() along with the sort() method with
the $natural parameter set to -1,
 as shown in the following ex:

db.cappedCollection.find().sort( { $natural: -1 } )

Check if a Collection is Capped

Use the isCapped() method to determine if a cl is capped, as follows:

db.cl.isCapped()

Convert a Collection to Capped
You can convert a non-capped cl to a capped cl with the
convertToCapped command:

db.runCommand({"convertToCapped": "mycoll", size: 100000});
The size parameter specifies the size of the capped cl in bytes.


This command obtains a global write lock and will block other opers
until it has completed.

Automatically Remove Data After a Specified Period of Time
For additional flexibility when expiring data,
consider MG’s TTL ixes,
 as described in Expire Data
from Collections by Setting TTL.
These ixes allow you to expire and rm data
from normal cls using a special type,
based on the value of a date-typed
field and a TTL value for the ix.

TTL Collections are not compatible with capped cls.



Tailable Cu
You can use a tailable cu with capped cls.
Similar to  tail -f ,
 the tailable cu “tails” the end of a capped cl.

  As new docs are inserted into the capped cl,
  you can use the tailable cu to continue retrieving docs.

See Create Tailable Cu for info on creating a tailable cu.
Create Tailable Cu

Overview

By default,
 MG will auto close a cu when the client 
 has exhausted all res in the cu.
 However, for capped cls you may use a Tailable Cu that remains open after the
  client exhausts the res in the initial cu. 
  Tailable cus are conceptually equivalent to the tail
   Unix command with the -f option (i.e. with “follow” mode). 
   After clients insert new additional docs into a capped cl, 
   the tailable cu will continue to retrieve docs.

Use tailable cus on capped cls that have high write volumes where ixes aren’t practical. 
For instance, MG replication uses tailable cus to tail the primary’s oplog.

NOTE
If your query is on an ixed field, do not use tailable cus, but instead, 
use a regular cu. Keep track of the last value of the ixed field returned by the query. 
To retrieve the newly added docs, query the cl again using the last value of the
 ixed field in the query criteria, as in the following ex:

db.<cl>.find( { ixedField: { $gt: <lastvalue> } } )
Consider the following behaviors related to tailable cus:

Tailable cus do not use ixes and return docs in natural order.
Because tailable cus do not use ixes, the initial scan for the query may be expensive; 
but, after initially exhausting the cu,
 subsequent retrievals of the newly added docs are inexpensive.
Tailable cus may become dead, or invalid, if either:
the query returns no match.
the cu returns the doc at the “end” of the cl and then 
the application deletes that doc.
A dead cu has an id of 0.
See your driver docation 
for the driver-specific method to specify the tailable cu.

C++ Example

The tail function uses a tailable cu 
to output the res from a query
 to a capped cl:

The function handles the case of the dead cu by having the query be inside a loop.
To periodically check for new data, the cu->more() statement is also inside a loop.
#include "client/dbclient.h"

using namespace mongo;

/*
 * Example of a tailable cu.
 * The function "tails" the capped cl (ns) and output elements as they are added.
 * The function also handles the possibility of a dead cu by tracking the field 'insertDate'.
 * New docs are added with increasing values of 'insertDate'.
 */

void tail(DBClientBase& conn, const char *ns) {
    BSONElement lastValue = minKey.firstElement()
    Query query = Query().hint( BSON( "$natural" << 1 ) );
    while ( 1 ) {  auto_ptr<DBClientCu> c =  conn.query(ns, query, 0, 0, 0, QueryOption_CuTailable | QueryOption_AwaitData );
        while ( 1 ) {            if ( !c->more() ) {    if ( c->isDead() ) {   break;  }
              continue}
            BSONObj o = c->next();            lastValue = o["insertDate"];            cout << o.toString() << endl; }
        query = QUERY( "insertDate" << GT << lastValue ).hint( BSON( "$natural" << 1 ) )   }}
The tail function performs the following actions:

Initialize the lastValue variable, which tracks the last accessed value. 
The function will use the lastValue if the cu becomes invalid and tail needs 
to restart the query. Use hint() to ensure that the query uses the $natural order.
In an outer while(1) loop,
Query the capped cl and return a tailable cu that blocks for several seconds
 waiting for new docs
auto_ptr<DBClientCu> c =
     conn.query(ns, query, 0, 0, 0,
                QueryOption_CuTailable | QueryOption_AwaitData );
Specify the capped cl using ns as an argument to the function.
Set the QueryOption_CuTailable option to create a tailable cu.
Set the QueryOption_AwaitData option so that the returned cu blocks for a few seconds to wait for data.
In an inner while (1) loop, read the docs from the cu:
If the cu has no more docs and is not invalid, loop the inner while loop to recheck 
for more docs.
If the cu has no more docs and is dead, break the inner while loop.
If the cu has docs:
output the doc,
up the lastValue value,
and loop the inner while (1) loop to recheck for more docs.
If the logic breaks out of the inner while (1) loop and the cu is invalid:
Use the lastValue value to create a new query condition that matches docs added after
 the lastValue. Explicitly ensure $natural order with the hint() method:
query = QUERY( "insertDate" << GT << lastValue ).hint( BSON( "$natural" << 1 ) );
Loop through the outer while (1) loop to re-query with the new query condition and repeat.

the tail of MG


  using MG as a messaging layer
  to maintain a log of all the messages
   passed between two clients.
While there are many dif  IPC schemes avail,
I thought it would be interesting to build something simple on top of MG
 using the tailable cu feature. 

In MG tailable cus can only be opened on capped cls. 
